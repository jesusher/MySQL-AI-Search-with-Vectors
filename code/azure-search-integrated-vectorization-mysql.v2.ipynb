{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Integrated Vectorization Sample\n",
    "This code demonstrates how to use Azure Cognitive Search as a Vector store by automatically chunking and generating embeddings using the Azure OpenAI Embedding skill as part of the skillset pipeline in Azure Cognitive Search. \n",
    "## Prerequisites\n",
    "To run the code, install the following packages. This was tested with Python v3.11.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requirements.txt --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    \n",
    "    VectorFilterMode,    \n",
    ")\n",
    "#from azure.search.documents.models import (\n",
    "   # RawVectorQuery,\n",
    " #   VectorizedQuery,\n",
    "   # QueryLanguage,\n",
    "#)\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    #AzureOpenAIParameters,  \n",
    "    #AzureOpenAIVectorizer,  \n",
    "    ExhaustiveKnnParameters,  \n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    FieldMapping,  \n",
    "    HnswParameters,  \n",
    "    #HnswVectorSearchAlgorithmConfiguration,\n",
    "    HnswAlgorithmConfiguration,  \n",
    "    #IndexProjectionMode,  \n",
    "    InputFieldMappingEntry,  \n",
    "    OutputFieldMappingEntry,  \n",
    "    SemanticPrioritizedFields,    \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SearchIndex,  \n",
    "    SearchIndexer,  \n",
    "    SearchIndexerDataContainer,  \n",
    "    SearchIndexerDataSourceConnection,  \n",
    "    #SearchIndexerIndexProjectionSelector,  \n",
    "    #SearchIndexerIndexProjections,  \n",
    "    #SearchIndexerIndexProjectionsParameters,  \n",
    "    SearchIndexerSkillset,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticField,  \n",
    "    SemanticSearch,  \n",
    "    SplitSkill,\n",
    "    SqlIntegratedChangeTrackingPolicy,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmKind,  \n",
    "    VectorSearchAlgorithmMetric,  \n",
    "    VectorSearchProfile,  \n",
    ")  \n",
    "#from azure.storage.blob import BlobServiceClient  \n",
    "import openai\n",
    "#import tiktoken\n",
    "\n",
    "#from openai.embeddings_utils import get_embedding\n",
    "from dotenv import load_dotenv  \n",
    "import os  \n",
    "#from openai import AzureOpenAIEmbeddingSkill\n",
    "  \n",
    "# Configure environment variables\n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME_01\")  \n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "model: str = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL\")\n",
    "blob_connection_string = os.getenv(\"BLOB_CONNECTION_STRING\")  \n",
    "container_name = os.getenv(\"BLOB_CONTAINER_NAME\")  \n",
    "credential = AzureKeyCredential(key)  \n",
    "EMBEDDING_LENGTH = 1536     # 768 for GPT-2, 1024 for GPT-3\n",
    "server = os.getenv(\"MYSQL_SERVER\")\n",
    "database = os.getenv(\"MYSQL_DATABASE\")\n",
    "username = os.getenv(\"MYSQL_USERNAME\")\n",
    "password = os.getenv(\"MYSQL_PASSWORD\")\n",
    "table_name = os.getenv(\"MYSQL_TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MySQL to a data source in Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conn_str = f'Server={server}; Port=3306; Database={database}; Uid={username}; Pwd={password}; SslMode=Preferred;'\n",
    "\n",
    "# Create a data source\n",
    "ds_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))\n",
    "container = SearchIndexerDataContainer(name=table_name)\n",
    "\n",
    "#change_detection_policy = SqlIntegratedChangeTrackingPolicy()\n",
    "\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-ds\",\n",
    "    type=\"mysql\",\n",
    "    connection_string=ds_conn_str,\n",
    "    container=container\n",
    "    #,data_change_detection_policy=change_detection_policy\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)  \n",
    "fields = [  \n",
    "  # Properties of individual chunk\n",
    "    SearchField(name=\"Id\", type=SearchFieldDataType.String, key=True,\n",
    "                sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),\n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), \n",
    "                vector_search_dimensions=EMBEDDING_LENGTH, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    # Properties of original row in DB that the chunk belonged to\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"parent_numero\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"parent_descripcion_breve\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"parent_descripcion\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True)\n",
    "\n",
    "]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            kind=VectorSearchAlgorithmKind.HNSW,  \n",
    "            parameters=HnswParameters(  \n",
    "                m=4,  \n",
    "                ef_construction=400,  \n",
    "                ef_search=500,  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "           # vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "            #vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    \n",
    ")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the vectorizer to the index you will need the version `11.4.0b12` of [azure-search-documents] which is a pre-release version. It's better to created it directly on the Azure Portal and do the reference to the Hnsw algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "                deployment_id=model,  \n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"Id\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticket-mysql-vector-02 created\n"
     ]
    }
   ],
   "source": [
    "# Create the semantic settings with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index with the semantic settings  \n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a skillset you will need the version `11.4.0b12` of [azure-search-documents] which is a pre-release version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ../whl/azure_search_documents-11.4.0b12-py3-none-any.whl --quiet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=300,  \n",
    "    page_overlap_length=20,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/descripcion\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "    deployment_id=model,  \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
    "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),\n",
    "               # InputFieldMappingEntry(name=\"Id\", source=\"/document/numero\"),\n",
    "                InputFieldMappingEntry(name=\"parent_numero\", source=\"/document/numero\"),\n",
    "                InputFieldMappingEntry(name=\"parent_descripcion_breve\", source=\"/document/descripcion_breve\"),\n",
    "                InputFieldMappingEntry(name=\"parent_descripcion\", source=\"/document/descripcion\")\n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill],  \n",
    "    index_projections=index_projections,  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ticket-mysql-vector-02-indexer created\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    #data_source_name=data_source.name,  \n",
    "    data_source_name=\"ticket-mysql-ds\",\n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"numero\", target_field_name=\"Id\")]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} created')  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openai import OpenA\n",
    "from anyio import sleep\n",
    "#get embeddings from azureopenai of a text \n",
    "def get_embeddings(text: str):\n",
    "    # There are a few ways to get embeddings. This is just one example.\n",
    "    # show me thee code generate embeddings from OpenAI from a text\n",
    "    \n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=openai.api_base,\n",
    "        api_key=openai.api_key,\n",
    "        api_version=openai.api_version,\n",
    "    )\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    count=0\n",
    "    while True:\n",
    "        try:\n",
    "            embedding = client.embeddings.create(input=[text], model=model)\n",
    "            break;\n",
    "        except openai.error.RateLimitError:\n",
    "            count+=1\n",
    "            print(f'RateLimitError Count: {count}')\n",
    "            sleep(2)\n",
    "    return embedding.data[0].embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: CHG0032603\n",
      "chunk_id: cd832933ff02_CHG0032603_pages_0\n",
      "Score: 0.8629935\n",
      "Content: SE REQUIERE LIBERAR LA APP DE MODIFICACION DE DATOS  EN ATENCION A FT RITM0123459 PARA LA CORRECCION DE LAS SIGUIENTES INCIDENCIAS.\n",
      "\n",
      "*SE ENCUENTRAN CON EL CAMPO VACÍO DE PAÍS EN LOS DATOS DE DOMICILIO PARTICULAR Y LABORAL.\n",
      "\n",
      "*TRAMITES DE APODERADO LEGAL LLEGABAN COMO BENEFICIARIO A PORTAL MIT\n"
     ]
    }
   ],
   "source": [
    "#from openai.embeddings_utils import get_embedding,\n",
    "# Pure Vector Search\n",
    "query = \"que se requiere para liberar la app afore?\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), fields=\"vector\", exhaustive=True, k_nearest_neighbors=3)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"Id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['Id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: CHG0032603\n",
      "chunk_id: cd832933ff02_CHG0032603_pages_0\n",
      "Score: 0.03333333507180214\n",
      "Content: SE REQUIERE LIBERAR LA APP DE MODIFICACION DE DATOS  EN ATENCION A FT RITM0123459 PARA LA CORRECCION DE LAS SIGUIENTES INCIDENCIAS.\n",
      "\n",
      "*SE ENCUENTRAN CON EL CAMPO VACÍO DE PAÍS EN LOS DATOS DE DOMICILIO PARTICULAR Y LABORAL.\n",
      "\n",
      "*TRAMITES DE APODERADO LEGAL LLEGABAN COMO BENEFICIARIO A PORTAL MIT\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"que se requiere para liberar la app afore?\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), fields=\"vector\", exhaustive=True, k_nearest_neighbors=3)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"Id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['Id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: CHG0032603\n",
      "chunk_id: cd832933ff02_CHG0032603_pages_0\n",
      "Reranker Score: 1.6374846696853638\n",
      "Content: SE REQUIERE LIBERAR LA APP DE MODIFICACION DE DATOS  EN ATENCION A FT RITM0123459 PARA LA CORRECCION DE LAS SIGUIENTES INCIDENCIAS.\n",
      "\n",
      "*SE ENCUENTRAN CON EL CAMPO VACÍO DE PAÍS EN LOS DATOS DE DOMICILIO PARTICULAR Y LABORAL.\n",
      "\n",
      "*TRAMITES DE APODERADO LEGAL LLEGABAN COMO BENEFICIARIO A PORTAL MIT\n",
      "Caption: \n",
      "\n",
      "parent_id: CHG0032599\n",
      "chunk_id: 33429450d544_CHG0032599_pages_0\n",
      "Reranker Score: 1.6374846696853638\n",
      "Content: SE REQUIERE LA ACTUALIZACIÓN DE LOS COMPONENTES DE ACTIVIDAD COMERCIAL, ESTUDIO DE RETIRO PERSONALIZADO Y PROSPECTA QUE INCLUYE LAS MEJORAS DE CORRECCIÓN DE HORARIO EN LA ZONA CST Y CAMBIO DE SQL LITE A SECURE STORAGE, MODIFICACIÓN IOS MENÚ PRINCIPAL.\n",
      "Caption: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Semantic Hybrid Search\n",
    "query = \"que se requiere para liberar la app afore?\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), fields=\"vector\", exhaustive=True, k_nearest_neighbors=3)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"Id\", \"chunk\"],\n",
    "    #query_type=QueryType.SEMANTIC, queryL=\"en-us\", semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=2\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['Id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

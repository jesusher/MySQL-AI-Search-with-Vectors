{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Integrated Vectorization Sample\n",
    "This code demonstrates how to use Azure Cognitive Search as a Vector store by automatically chunking and generating embeddings using the Azure OpenAI Embedding skill as part of the skillset pipeline in Azure Cognitive Search. \n",
    "## Prerequisites\n",
    "To run the code, install the following packages. This was tested with Python v3.11.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-storage-blob --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.6.0\n",
      "Uninstalling openai-1.6.0:\n",
      "  Successfully uninstalled openai-1.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall openai --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: azure-search-documents 11.4.0\n",
      "Uninstalling azure-search-documents-11.4.0:\n",
      "  Successfully uninstalled azure-search-documents-11.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall azure_search_documents --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ../whl/azure_search_documents-11.4.0b12-py3-none-any.whl --quiet  \n",
    "! pip install openai azure-storage-blob python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotated-types==0.6.0\n",
      "anyio==4.2.0\n",
      "asttokens==2.4.1\n",
      "azure-common==1.1.28\n",
      "azure-core==1.29.6\n",
      "azure-search-documents==11.4.0\n",
      "azure-storage-blob==12.19.0\n",
      "certifi==2023.11.17\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "colorama==0.4.6\n",
      "comm==0.2.0\n",
      "contourpy==1.2.0\n",
      "cryptography==41.0.7\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.0\n",
      "decorator==5.1.1\n",
      "distro==1.8.0\n",
      "executing==2.0.1\n",
      "fonttools==4.47.0\n",
      "h11==0.14.0\n",
      "httpcore==1.0.2\n",
      "httpx==0.25.2\n",
      "idna==3.6\n",
      "ipykernel==6.27.1\n",
      "ipython==8.18.1\n",
      "isodate==0.6.1\n",
      "jedi==0.19.1\n",
      "joblib==1.3.2\n",
      "jupyter_client==8.6.0\n",
      "jupyter_core==5.5.1\n",
      "kiwisolver==1.4.5\n",
      "matplotlib==3.8.2\n",
      "matplotlib-inline==0.1.6\n",
      "nest-asyncio==1.5.8\n",
      "numpy==1.26.2\n",
      "openai==1.6.0\n",
      "packaging==23.2\n",
      "parso==0.8.3\n",
      "Pillow==10.1.0\n",
      "platformdirs==4.1.0\n",
      "plotly==5.18.0\n",
      "prompt-toolkit==3.0.43\n",
      "psutil==5.9.7\n",
      "pure-eval==0.2.2\n",
      "pycparser==2.21\n",
      "pydantic==2.5.2\n",
      "pydantic_core==2.14.5\n",
      "Pygments==2.17.2\n",
      "pyparsing==3.1.1\n",
      "python-dateutil==2.8.2\n",
      "python-dotenv==1.0.0\n",
      "pywin32==306\n",
      "pyzmq==25.1.2\n",
      "regex==2023.10.3\n",
      "requests==2.31.0\n",
      "scipy==1.11.4\n",
      "six==1.16.0\n",
      "sniffio==1.3.0\n",
      "stack-data==0.6.3\n",
      "tenacity==8.2.3\n",
      "threadpoolctl==3.2.0\n",
      "tiktoken==0.5.2\n",
      "tornado==6.4\n",
      "tqdm==4.66.1\n",
      "traitlets==5.14.0\n",
      "typing_extensions==4.9.0\n",
      "urllib3==2.1.0\n",
      "wcwidth==0.2.12\n"
     ]
    }
   ],
   "source": [
    "! pip freeze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VectorizedQuery' from 'azure.search.documents.models' (f:\\TestMySQLAISearch\\MySQL-AI-Search-with-Vectors\\env-openai-pyth3-11\\Lib\\site-packages\\azure\\search\\documents\\models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mf:\\TestMySQLAISearch\\MySQL-AI-Search-with-Vectors\\code\\azure-search-integrated-vectorization-mysql.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m \u001b[39mimport\u001b[39;00m SearchClient  \n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m \u001b[39mimport\u001b[39;00m SearchIndexClient, SearchIndexerClient  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     QueryAnswerType,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     QueryCaptionType,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     QueryType,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     VectorizedQuery,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     VectorFilterMode,    \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#from azure.search.documents.models import (\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m    \u001b[39m# RawVectorQuery,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m  \u001b[39m#   VectorizedQuery,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m    \u001b[39m# QueryLanguage,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m#AzureOpenAIParameters,  \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m#AzureOpenAIVectorizer,  \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     VectorSearchProfile,  \n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/TestMySQLAISearch/MySQL-AI-Search-with-Vectors/code/azure-search-integrated-vectorization-mysql.ipynb#X16sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )  \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'VectorizedQuery' from 'azure.search.documents.models' (f:\\TestMySQLAISearch\\MySQL-AI-Search-with-Vectors\\env-openai-pyth3-11\\Lib\\site-packages\\azure\\search\\documents\\models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import required libraries  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    \n",
    "    VectorFilterMode,    \n",
    ")\n",
    "#from azure.search.documents.models import (\n",
    "   # RawVectorQuery,\n",
    " #   VectorizedQuery,\n",
    "   # QueryLanguage,\n",
    "#)\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    #AzureOpenAIParameters,  \n",
    "    #AzureOpenAIVectorizer,  \n",
    "    ExhaustiveKnnParameters,  \n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    FieldMapping,  \n",
    "    HnswParameters,  \n",
    "    #HnswVectorSearchAlgorithmConfiguration,\n",
    "    HnswAlgorithmConfiguration,  \n",
    "    #IndexProjectionMode,  \n",
    "    InputFieldMappingEntry,  \n",
    "    OutputFieldMappingEntry,  \n",
    "    SemanticPrioritizedFields,    \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SearchIndex,  \n",
    "    SearchIndexer,  \n",
    "    SearchIndexerDataContainer,  \n",
    "    SearchIndexerDataSourceConnection,  \n",
    "    #SearchIndexerIndexProjectionSelector,  \n",
    "    #SearchIndexerIndexProjections,  \n",
    "    #SearchIndexerIndexProjectionsParameters,  \n",
    "    SearchIndexerSkillset,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticField,  \n",
    "    SemanticSearch,  \n",
    "    SplitSkill,\n",
    "    SqlIntegratedChangeTrackingPolicy,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmKind,  \n",
    "    VectorSearchAlgorithmMetric,  \n",
    "    VectorSearchProfile,  \n",
    ")  \n",
    "#from azure.storage.blob import BlobServiceClient  \n",
    "import openai\n",
    "\n",
    "#from openai.embeddings_utils import get_embedding\n",
    "from dotenv import load_dotenv  \n",
    "import os  \n",
    "from openai import AzureOpenAIEmbeddingSkill\n",
    "  \n",
    "# Configure environment variables\n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME_01\")  \n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "model: str = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL\")\n",
    "blob_connection_string = os.getenv(\"BLOB_CONNECTION_STRING\")  \n",
    "container_name = os.getenv(\"BLOB_CONTAINER_NAME\")  \n",
    "credential = AzureKeyCredential(key)  \n",
    "EMBEDDING_LENGTH = 1536     # 768 for GPT-2, 1024 for GPT-3\n",
    "server = os.getenv(\"MYSQL_SERVER\")\n",
    "database = os.getenv(\"MYSQL_DATABASE\")\n",
    "username = os.getenv(\"MYSQL_USERNAME\")\n",
    "password = os.getenv(\"MYSQL_PASSWORD\")\n",
    "table_name = os.getenv(\"MYSQL_TABLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MySQL to a data source in Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conn_str = f'Server={server}; Port=3306; Database={database}; Uid={username}; Pwd={password}; SslMode=Preferred;'\n",
    "\n",
    "# Create a data source\n",
    "ds_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))\n",
    "container = SearchIndexerDataContainer(name=table_name)\n",
    "\n",
    "#change_detection_policy = SqlIntegratedChangeTrackingPolicy()\n",
    "\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-ds\",\n",
    "    type=\"mysql\",\n",
    "    connection_string=ds_conn_str,\n",
    "    container=container\n",
    "    #,data_change_detection_policy=change_detection_policy\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)  \n",
    "fields = [  \n",
    "  # Properties of individual chunk\n",
    "    SearchField(name=\"Id\", type=SearchFieldDataType.String, key=True,\n",
    "                sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),\n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), \n",
    "                vector_search_dimensions=EMBEDDING_LENGTH, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    # Properties of original row in DB that the chunk belonged to\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"parent_numero\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"parent_descripcion_breve\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),\n",
    "    SearchField(name=\"parent_descripcion\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True)\n",
    "\n",
    "]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(  \n",
    "            name=\"myHnsw\",  \n",
    "            kind=VectorSearchAlgorithmKind.HNSW,  \n",
    "            parameters=HnswParameters(  \n",
    "                m=4,  \n",
    "                ef_construction=400,  \n",
    "                ef_search=500,  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "        ExhaustiveKnnAlgorithmConfiguration(  \n",
    "            name=\"myExhaustiveKnn\",  \n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,  \n",
    "            parameters=ExhaustiveKnnParameters(  \n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "           # vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myExhaustiveKnnProfile\",  \n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
    "            #vectorizer=\"myOpenAI\",  \n",
    "        ),  \n",
    "    ],  \n",
    "    \n",
    ")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the vectorizer to the index you will need the version `11.4.0b12` of [azure-search-documents] which is a pre-release version. It's better to created it directly on the Azure Portal and do the reference to the Hnsw algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "                deployment_id=model,  \n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "            ),  \n",
    "        ),  \n",
    "    ],  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"Id\")]  \n",
    "    ),  \n",
    ")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticket-mysql-vector-02 created\n"
     ]
    }
   ],
   "source": [
    "# Create the semantic settings with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index with the semantic settings  \n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a skillset you will need the version `11.4.0b12` of [azure-search-documents] which is a pre-release version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ../whl/azure_search_documents-11.4.0b12-py3-none-any.whl --quiet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=300,  \n",
    "    page_overlap_length=20,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/descripcion\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
    "    deployment_id=model,  \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
    "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),\n",
    "               # InputFieldMappingEntry(name=\"Id\", source=\"/document/numero\"),\n",
    "                InputFieldMappingEntry(name=\"parent_numero\", source=\"/document/numero\"),\n",
    "                InputFieldMappingEntry(name=\"parent_descripcion_breve\", source=\"/document/descripcion_breve\"),\n",
    "                InputFieldMappingEntry(name=\"parent_descripcion\", source=\"/document/descripcion\")\n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ")  \n",
    "  \n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=[split_skill, embedding_skill],  \n",
    "    index_projections=index_projections,  \n",
    ")  \n",
    "  \n",
    "client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ticket-mysql-vector-02-indexer created\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "  \n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    #data_source_name=data_source.name,  \n",
    "    data_source_name=\"ticket-mysql-ds\",\n",
    "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
    "    field_mappings=[FieldMapping(source_field_name=\"numero\", target_field_name=\"Id\")]  \n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} created')  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openai import OpenA\n",
    "from anyio import sleep\n",
    "#get embeddings from azureopenai of a text \n",
    "def get_embeddings(text: str):\n",
    "    # There are a few ways to get embeddings. This is just one example.\n",
    "    # show me thee code generate embeddings from OpenAI from a text\n",
    "    \n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=openai.api_base,\n",
    "        api_key=openai.api_key,\n",
    "        api_version=openai.api_version,\n",
    "    )\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    count=0\n",
    "    while True:\n",
    "        try:\n",
    "            embedding = client.embeddings.create(input=[text], model=model)\n",
    "            break;\n",
    "        except openai.error.RateLimitError:\n",
    "            count+=1\n",
    "            print(f'RateLimitError Count: {count}')\n",
    "            sleep(2)\n",
    "    return embedding.data[0].embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: CHG0032603\n",
      "chunk_id: fc1e95c56882_CHG0032603_pages_0\n",
      "Score: 0.8629935\n",
      "Content: SE REQUIERE LIBERAR LA APP DE MODIFICACION DE DATOS  EN ATENCION A FT RITM0123459 PARA LA CORRECCION DE LAS SIGUIENTES INCIDENCIAS.\n",
      "\n",
      "*SE ENCUENTRAN CON EL CAMPO VACÍO DE PAÍS EN LOS DATOS DE DOMICILIO PARTICULAR Y LABORAL.\n",
      "\n",
      "*TRAMITES DE APODERADO LEGAL LLEGABAN COMO BENEFICIARIO A PORTAL MIT\n"
     ]
    }
   ],
   "source": [
    "#from openai.embeddings_utils import get_embedding,\n",
    "# Pure Vector Search\n",
    "query = \"que se requiere para liberar la app afore?\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), fields=\"vector\", exhaustive=True, k_nearest_neighbors=3)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"Id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['Id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: CHG0032603\n",
      "chunk_id: fc1e95c56882_CHG0032603_pages_0\n",
      "Score: 0.03333333507180214\n",
      "Content: SE REQUIERE LIBERAR LA APP DE MODIFICACION DE DATOS  EN ATENCION A FT RITM0123459 PARA LA CORRECCION DE LAS SIGUIENTES INCIDENCIAS.\n",
      "\n",
      "*SE ENCUENTRAN CON EL CAMPO VACÍO DE PAÍS EN LOS DATOS DE DOMICILIO PARTICULAR Y LABORAL.\n",
      "\n",
      "*TRAMITES DE APODERADO LEGAL LLEGABAN COMO BENEFICIARIO A PORTAL MIT\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"que se requiere para liberar la app afore?\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), fields=\"vector\", exhaustive=True, k_nearest_neighbors=3)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"Id\", \"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['Id']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['chunk']}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search + semantic reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: CHG0032603\n",
      "chunk_id: fc1e95c56882_CHG0032603_pages_0\n",
      "Reranker Score: 1.6374846696853638\n",
      "Content: SE REQUIERE LIBERAR LA APP DE MODIFICACION DE DATOS  EN ATENCION A FT RITM0123459 PARA LA CORRECCION DE LAS SIGUIENTES INCIDENCIAS.\n",
      "\n",
      "*SE ENCUENTRAN CON EL CAMPO VACÍO DE PAÍS EN LOS DATOS DE DOMICILIO PARTICULAR Y LABORAL.\n",
      "\n",
      "*TRAMITES DE APODERADO LEGAL LLEGABAN COMO BENEFICIARIO A PORTAL MIT\n",
      "Caption: \n",
      "\n",
      "parent_id: CHG0032599\n",
      "chunk_id: 9a3364acbb75_CHG0032599_pages_0\n",
      "Reranker Score: 1.6374846696853638\n",
      "Content: SE REQUIERE LA ACTUALIZACIÓN DE LOS COMPONENTES DE ACTIVIDAD COMERCIAL, ESTUDIO DE RETIRO PERSONALIZADO Y PROSPECTA QUE INCLUYE LAS MEJORAS DE CORRECCIÓN DE HORARIO EN LA ZONA CST Y CAMBIO DE SQL LITE A SECURE STORAGE, MODIFICACIÓN IOS MENÚ PRINCIPAL.\n",
      "Caption: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Semantic Hybrid Search\n",
    "query = \"que se requiere para liberar la app afore?\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), fields=\"vector\", exhaustive=True, k_nearest_neighbors=3)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"Id\", \"chunk\"],\n",
    "    #query_type=QueryType.SEMANTIC, queryL=\"en-us\", semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=2\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"chunk_id: {result['Id']}\")  \n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
